{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this file \n",
    "# we train the MeasureVAE \"Learning to Traverse Latent Spaces for Musical Score Inpainting\", published in ISMIR 2019\n",
    "# The core model code is from their releasing code.\n",
    "\n",
    "from MeasureVAE.measure_vae import MeasureVAE\n",
    "from utils.helpers import *\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import random\n",
    "from data_processor import DatasetProcessor\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "data_path = [\n",
    "    \"data/bachinv_1.npy\",\n",
    "    \"data/bachinv_2.npy\"\n",
    "]\n",
    "\n",
    "# paramters initialization\n",
    "num_notes = 86\n",
    "note_embedding_dim=10\n",
    "metadata_embedding_dim=2\n",
    "num_encoder_layers=2\n",
    "encoder_hidden_size=512\n",
    "encoder_dropout_prob=0.5\n",
    "has_metadata=False\n",
    "latent_space_dim=512\n",
    "num_decoder_layers=2\n",
    "decoder_hidden_size=512\n",
    "decoder_dropout_prob=0.5\n",
    "batch_size=128\n",
    "num_epochs=50\n",
    "train=True\n",
    "plot=False\n",
    "log=True\n",
    "lr=1e-4\n",
    "seq_len = 8 * 6\n",
    "n_epochs = 50\n",
    "save_period = 5\n",
    "ratio = [0.8,0.2,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "trainset = []\n",
    "validset = []\n",
    "for dpath in data_path:\n",
    "    dp = DatasetProcessor(data = dpath)\n",
    "    dp.split(ratio[::])\n",
    "    trainset += dp.process(dataset = dp.trainset, vae = \"MeasureVAE\", spb = 48, bar_num = 1 , shift_note = [-4,-3,-2,-1,0,1,2,3,4])\n",
    "    validset += dp.process(dataset = dp.validset, vae = \"MeasureVAE\", spb = 48, bar_num = 1, shift_note = [-4,-3,-2,-1,0,1,2,3,4])\n",
    "trainset = torch.from_numpy(np.array(trainset)).long()\n",
    "validset = torch.from_numpy(np.array(validset)).long()\n",
    "print(trainset.size(), validset.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TensorDataset(trainset)\n",
    "validset = TensorDataset(validset)\n",
    "train_loader = DataLoader(dataset = trainset, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(dataset = validset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def compute_kld_loss(z_dist, prior_dist, beta=0.001):\n",
    "    \"\"\"\n",
    "\n",
    "    :param z_dist: torch.nn.distributions object\n",
    "    :param prior_dist: torch.nn.distributions\n",
    "    :param beta:\n",
    "    :return: kl divergence loss\n",
    "    \"\"\"\n",
    "    kld = torch.distributions.kl.kl_divergence(z_dist, prior_dist)\n",
    "    kld = beta * kld.sum(1).mean()\n",
    "    return kld\n",
    "\n",
    "def mean_crossentropy_loss(weights, targets):\n",
    "    \"\"\"\n",
    "    Evaluates the cross entropy loss\n",
    "    :param weights: torch Variable,\n",
    "            (batch_size, seq_len, num_notes)\n",
    "    :param targets: torch Variable,\n",
    "            (batch_size, seq_len)\n",
    "    :return: float, loss\n",
    "    \"\"\"\n",
    "    criteria = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "    batch_size, seq_len, num_notes = weights.size()\n",
    "    weights = weights.contiguous().view(-1, num_notes)\n",
    "    targets = targets.contiguous().view(-1)\n",
    "    loss = criteria(weights, targets)\n",
    "    return loss\n",
    "\n",
    "def mean_accuracy(weights, targets):\n",
    "    \"\"\"\n",
    "    Evaluates the mean accuracy in prediction\n",
    "    :param weights: torch Variable,\n",
    "            (batch_size, seq_len, num_notes)\n",
    "    :param targets: torch Variable,\n",
    "            (batch_size, seq_len)\n",
    "    :return float, accuracy\n",
    "    \"\"\"\n",
    "    _, _, num_notes = weights.size()\n",
    "    weights = weights.contiguous().view(-1, num_notes)\n",
    "    targets = targets.contiguous().view(-1)\n",
    "\n",
    "    _, max_indices = weights.max(1)\n",
    "    correct = max_indices == targets\n",
    "    return torch.sum(correct.float()) / targets.size(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import measureVAE\n",
    "save_path = \"model_backup/\"\n",
    "model = MeasureVAE(\n",
    "    num_notes = num_notes,\n",
    "    note_embedding_dim=note_embedding_dim,\n",
    "    metadata_embedding_dim=metadata_embedding_dim,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    encoder_hidden_size=encoder_hidden_size,\n",
    "    encoder_dropout_prob=encoder_dropout_prob,\n",
    "    latent_space_dim=latent_space_dim,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    decoder_hidden_size=decoder_hidden_size,\n",
    "    decoder_dropout_prob=decoder_dropout_prob,\n",
    "    has_metadata=has_metadata\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "if torch.cuda.is_available():\n",
    "    print('Using: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using: CPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "model.train()\n",
    "step = 0\n",
    "for epoch in range(n_epochs):\n",
    "    tlen = len(train_loader)\n",
    "    vlen = len(valid_loader)\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    total_vloss = 0.0\n",
    "    total_vacc = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        model.train()\n",
    "        x = data[0]\n",
    "        target = x.view(-1)\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        weights, samples, z_dist, prior_dist, z_tilde, z_prior = model(measure_score_tensor=x,train=True)\n",
    "        recons_loss = mean_crossentropy_loss(weights=weights, targets=target)\n",
    "        dist_loss = compute_kld_loss(z_dist, prior_dist)\n",
    "        loss = recons_loss + dist_loss\n",
    "        accuracy = mean_accuracy(weights=weights,targets=target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        print(\"epoch: %d batch: %d/%d loss: %.5f acc: %.5f\"  % (epoch, i, tlen, loss.item(), accuracy.item()),end = \"\\r\")\n",
    "        total_loss += loss.item()\n",
    "        total_acc += accuracy.item()\n",
    "        \n",
    "    for i,data in enumerate(valid_loader):\n",
    "        model.eval()\n",
    "        v_x = data[0]\n",
    "        v_target = v_x.view(-1)\n",
    "        if torch.cuda.is_available():\n",
    "            v_x = v_x.cuda()\n",
    "            v_target = v_target.cuda()\n",
    "        with torch.no_grad():\n",
    "            v_weights, v_samples, v_z_dist, v_prior_dist, v_z_tilde, v_z_prior = model(measure_score_tensor=v_x,train=False)\n",
    "            v_recons_loss = mean_crossentropy_loss(weights=v_weights, targets=v_target)\n",
    "            v_dist_loss = compute_kld_loss(v_z_dist, v_prior_dist)\n",
    "            v_loss = v_recons_loss + v_dist_loss\n",
    "            v_accuracy = mean_accuracy(weights=v_weights,targets=v_target)\n",
    "            total_vloss += v_loss.item()\n",
    "            total_vacc += v_accuracy.item()\n",
    "        print(\"epoch: %d batch: %d/%d val loss: %.5f val acc: %.5f\"  % (epoch ,i, vlen, v_loss.item(), v_accuracy.item()),end = \"\\r\")\n",
    "    total_loss /= tlen\n",
    "    total_acc /= tlen\n",
    "    total_vloss /= vlen\n",
    "    total_vacc /= vlen\n",
    "    print(\"epoch: %d loss: %.5f acc: %.5f val_loss: %.5f val_acc: %.5f\"  % (epoch, total_loss, total_acc, total_vloss, total_vacc))\n",
    "            \n",
    "        \n",
    "    if (epoch + 1) % save_period == 0:\n",
    "        filename = \"measure-vae-\" + 'loss_' + str(total_loss) + \"_\" + str(total_acc) + \"_\" + str(epoch+1) + \".pt\"\n",
    "        torch.save(model.cpu().state_dict(),save_path + filename)\n",
    "        model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
